{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNaiJjr283PlMCndqMmBv3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voyageran/StartNN/blob/main/Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjSehYZBVxQK",
        "outputId": "91abede6-516c-49b5-e9cb-5ec2293adcd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l' -> '/content/d2l'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/paddle.py' -> '/content/d2l/paddle.py'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/mxnet.py' -> '/content/d2l/mxnet.py'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/tensorflow.py' -> '/content/d2l/tensorflow.py'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/torch.py' -> '/content/d2l/torch.py'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__init__.py' -> '/content/d2l/__init__.py'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__pycache__' -> '/content/d2l/__pycache__'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__pycache__/mxnet.cpython-310.pyc' -> '/content/d2l/__pycache__/mxnet.cpython-310.pyc'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__pycache__/__init__.cpython-310.pyc' -> '/content/d2l/__pycache__/__init__.cpython-310.pyc'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__pycache__/torch.cpython-310.pyc' -> '/content/d2l/__pycache__/torch.cpython-310.pyc'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__pycache__/tensorflow.cpython-310.pyc' -> '/content/d2l/__pycache__/tensorflow.cpython-310.pyc'\n",
            "'/content/gdrive/MyDrive/Colab Notebooks/d2l/__pycache__/paddle.cpython-310.pyc' -> '/content/d2l/__pycache__/paddle.cpython-310.pyc'\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "sys.path.insert(0,\"/content/content/notebooks/colabInstallPackage\")\n",
        "\n",
        "!cp -av '/content/gdrive/MyDrive/Colab Notebooks/d2l' '/content/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **卷积（操作子）**"
      ],
      "metadata": {
        "id": "RqTHGpy5MUGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why 卷积？**"
      ],
      "metadata": {
        "id": "mVUgsSAKWv3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification for cat and dog images**"
      ],
      "metadata": {
        "id": "l7TgkjyfWIYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "为什么不用但隐藏层MLP？\n",
        "\n",
        "我们来做个假设。设我们收集到的图片是12M，RGB三个通道，所以36M，如果使用100神经元的单隐藏层MLP，那么模型有3.6B元素。这么多元素比世界上所有猫狗总和还多，不如直接把所有手动标记。"
      ],
      "metadata": {
        "id": "DCj9b7NYWO6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**遵循规则**：\n",
        "\n",
        "\n",
        "e.g.，在一张图片中用识别器找一个人\n",
        "1.   平移不变性：识别器在图片的每个位置都是一样的\n",
        "2.   局部性：可以只用看局部信息\n",
        "\n"
      ],
      "metadata": {
        "id": "hSxwkmwBXUtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **卷积是特殊的全连接层**"
      ],
      "metadata": {
        "id": "rGd5jOQNXDXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "普通全连接层，把每张图片vectorize成a vector，做全连接的时候需要一个二维的weight matrix。\n",
        "\n",
        "现在我们不把图片（input+output）打散，保留空间结构。即还存在宽度和高度。那么存权重的应该是个四维张量（ij存输出，kl管输入），\n",
        "$$\n",
        "h_{ij} = \\sum_{k,l}w_{i,j,k,l}x_{k,l} = \\sum_{a,b}v_{i,j,a,b} x_{i+a,j+b}\n",
        "$$\n",
        "Where $k = i+a$, $l = j+b$. $V$是$W$的重新索引。"
      ],
      "metadata": {
        "id": "pke79XT2aeLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**原则一：平移不变性**\n",
        "\n",
        "现在$h_{i,j} = \\sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}$中，$v_{i,j,a,b}$依赖于$(i,j)$\n",
        "\n",
        "***Solution***:\n",
        "\n",
        "Let $v_{i,j,a,b} = v_{a,b}$, then\n",
        "$$\n",
        "h_{i,j} = \\sum_{a,b}v_{a,b} x_{i+a,j+b}\n",
        "$$\n",
        "这是2D交叉相关（DL叫卷积，不严谨，因为卷积是反着走的，应该a->(-a),b->(-b)）。不用存那么多权重。"
      ],
      "metadata": {
        "id": "Woq1fXX-IZKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**原则二：局部性**\n",
        "$$\n",
        "h_{i,j} = \\sum_{a,b}v_{a,b} x_{i+a,j+b}\n",
        "$$\n",
        "我们只想看部分。\n",
        "\n",
        "***Solution***:\n",
        "\n",
        "远离一定范围的时候，权重为0。写成公式为：\n",
        "$|a|,|b|> Δ$ such that $v_{a,b}=0$,\n",
        "$$\n",
        "h_{i,j} = \\sum_{a=-Δ}^{Δ}\\sum_{b=-Δ}^{Δ}x_{i+a,j+b}\n",
        "$$\n",
        "控制$a,b$的范围。"
      ],
      "metadata": {
        "id": "e12on1S6JQrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **卷积层**"
      ],
      "metadata": {
        "id": "qFp3lL0EMaVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "E.g.，\n",
        "\n",
        "Input:\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "0&1&2\\\\\n",
        "3&4&5\\\\\n",
        "6&7&8\n",
        "\\end{bmatrix}\n",
        "$\n",
        "Kernel:\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "0&1\\\\\n",
        "2&3\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "Output:\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "19&25\\\\\n",
        "37&43\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "算法：\n",
        "$0\\times 0+1\\times 1+2\\times 3+3\\times 4 = 19$\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "zniB6zrsMeW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以用不同的核做 边缘检测、锐化、高斯模糊。"
      ],
      "metadata": {
        "id": "QCe83Kc9nhZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1D\n",
        "$$\n",
        "y_{i} = \\sum_{a=1}^{h}w_{a}x_{i+a}\n",
        "$$\n",
        "文本、语言、时间序列\n",
        "\n",
        "- 3D\n",
        "$$\n",
        "y_{i,j,k} = \\sum_{a=1}^{h}\\sum_{b=1}^{w}\\sum_{c=1}^{d} w_{a,b,c}x_{i+a,j+b,k+c}\n",
        "$$\n",
        "Videos, medical images （核磁共振）, 气象地图（时间轴）"
      ],
      "metadata": {
        "id": "TYFYyewWqPVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 卷积层将input和kernel进行交叉相关，加上bias后得到output。\n",
        "- Kernel和bias是可以学习的params\n",
        "- The size of kernel matrix is a hyper-parameter。"
      ],
      "metadata": {
        "id": "Cp0Eif3CtLlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "ZftCD1YsV8hM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d(X, K):\n",
        "  \"\"\"Compute 2d corr\"\"\"\n",
        "  h, w = K.shape #K:kernel\n",
        "  Y = torch.zeros((X.shape[0]-h+1, X.shape[1]-w+1))\n",
        "  for i in range(Y.shape[0]):\n",
        "    for j in range(Y.shape[1]):\n",
        "      Y[i,j] = (X[i: i+h, j: j+w] *K).sum()\n",
        "  return Y"
      ],
      "metadata": {
        "id": "_s3bCC6buEer"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otiGAvdQS7Mb",
        "outputId": "6c5f15f8-d6ef-44ad-cbe1-52c399ae835f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 25.],\n",
              "        [37., 43.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D convolution\n",
        "class Conv2D(nn.Module):\n",
        "  def __init__(self, kernel_size):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.rand(kernel_size))\n",
        "    self.bias = nn.Prameters(torch.zeros(1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return corr2d(x, self.weight) + self.bias"
      ],
      "metadata": {
        "id": "p5eDh0FlTIPS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 边缘检测\n",
        "# black:0, white:1\n",
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buvyt1pkVuls",
        "outputId": "b0a26456-21f1-46fa-b01f-770e1107d081"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[1.0,-1.0]]) #水平相邻的两元素相同，则输出为零，否则输出为非零。"
      ],
      "metadata": {
        "id": "rXGZEnlvWe5v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = corr2d(X, K) # 黑变白：-1， 白变黑：1\n",
        "Y #只能检测垂直边缘"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtQMrLNfWmm3",
        "outputId": "b743e728-1553-4f3b-9302-422302e00c37"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X.t(), K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v7RCmT3Wsnp",
        "outputId": "d8cd8ef2-5ceb-4115-8ae5-1c0359dd7662"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given `X` and `Y`, learn the kernel `K`"
      ],
      "metadata": {
        "id": "6ZZAk-ZTenmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Conv2d\n",
        "conv2d = nn.Conv2d(1,1, kernel_size=(1,2), bias = False) #1，1：输入输出通道均为1\n",
        "\n",
        "X = X.reshape((1,1,6,8))\n",
        "Y = Y.reshape((1,1,6,7))\n",
        "\n",
        "for i in range(10):\n",
        "  Y_hat = conv2d(X)\n",
        "  l = (Y_hat - Y)**2\n",
        "  conv2d.zero_grad()\n",
        "  l.sum().backward()\n",
        "  conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n",
        "  if (i+1) % 2 ==0:\n",
        "    print(f'batch{i+1}, loss{l.sum():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnGooO9geh4w",
        "outputId": "2126eefb-30e0-43d7-c0a3-327ab83f0578"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch2, loss11.268\n",
            "batch4, loss2.573\n",
            "batch6, loss0.712\n",
            "batch8, loss0.234\n",
            "batch10, loss0.086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d.weight.data.reshape((1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "060MVnO6r3o9",
        "outputId": "4f8e4505-cb21-40bb-aa31-5aa33c48a821"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9558, -1.0140]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}